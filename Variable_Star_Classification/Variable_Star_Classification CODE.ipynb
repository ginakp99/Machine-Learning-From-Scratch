{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- Constants for Local Files ---\n",
        "TRAIN_X_FILE = \"X_train_binary.csv\"\n",
        "TRAIN_Y_FILE = \"y_train_binary.csv\"\n",
        "TEST_X_FILE = \"X_test_binary.csv\"\n",
        "TEST_Y_FILE = \"y_test_binary.csv\"\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# TASK 2.1: Data Understanding and Preprocessing\n",
        "# -----------------------------------------------------------------\n",
        "def load_and_preprocess_data():\n",
        "    \"\"\"Loads, reports frequencies, and standardizes the data.\"\"\"\n",
        "    print(\"--- Task 2.1: Data Loading ---\")\n",
        "    try:\n",
        "        # Load X and y training and test data\n",
        "        X_train = np.loadtxt(TRAIN_X_FILE, delimiter=',')\n",
        "        y_train = np.loadtxt(TRAIN_Y_FILE, delimiter=',')\n",
        "        X_test = np.loadtxt(TEST_X_FILE, delimiter=',')\n",
        "        y_test = np.loadtxt(TEST_Y_FILE, delimiter=',')\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: One or more data files not found in the directory.\")\n",
        "        raise\n",
        "\n",
        "    # 1. Report number of training/test samples\n",
        "    print(f\"Number of training samples: {X_train.shape[0]}\")\n",
        "    print(f\"Number of test samples:     {X_test.shape[0]}\")\n",
        "\n",
        "    # 2. Report Class Frequencies\n",
        "    y_train_series = pd.Series(y_train)\n",
        "    counts = y_train_series.value_counts(normalize=True).sort_index()\n",
        "    print(\"\\nTraining Class Frequencies:\")\n",
        "    for label, freq in counts.items():\n",
        "        print(f\"  Class {int(label)}: {freq:.2%}\")\n",
        "\n",
        "    # 3. Normalize Input Data (f_norm)\n",
        "    # StandardScaler computes mean/variance from X_train (f_norm) and applies it.\n",
        "    # This aligns with the theory that normalization is part of the model building process.\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "    # Apply the SAME f_norm to the test data (Crucial Rule against data leakage!)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Verification\n",
        "    print(\"\\nVerification of Transformed Test Data (Feature 10):\")\n",
        "    # Feature 10 is used for quick check\n",
        "    print(f\"  Mean (should be near 0): {np.mean(X_test_scaled[:, 10]):.4f}\")\n",
        "    print(f\"  Variance (should be near 1): {np.var(X_test_scaled[:, 10]):.4f}\")\n",
        "\n",
        "    return X_train_scaled, y_train, X_test_scaled, y_test\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# TASK 2.2: Model Selection using Grid-Search\n",
        "# -----------------------------------------------------------------\n",
        "def run_grid_search(X_train, y_train):\n",
        "    \"\"\"Performs 5-fold CV Grid Search to find optimal C and gamma.\"\"\"\n",
        "\n",
        "    # Define the search grid (logarithmic scale is common practice)\n",
        "    C_values = np.logspace(-2, 2, 5)  # [0.01, 0.1, 1, 10, 100]\n",
        "    gamma_values = np.logspace(-3, 1, 5) # [0.001, 0.01, 0.1, 1, 10]\n",
        "\n",
        "    param_grid = {'C': C_values, 'gamma': gamma_values}\n",
        "\n",
        "    # Initialize the SVM model (Gaussian/RBF kernel)\n",
        "    svm_base = SVC(kernel='rbf', random_state=42)\n",
        "\n",
        "    # Use GridSearchCV with 5-fold Cross-Validation (cv=5)\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=svm_base,\n",
        "        param_grid=param_grid,\n",
        "        scoring='accuracy',\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(\"\\n--- Task 2.2: Starting Grid Search ---\")\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    return grid_search\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# TASK 2.3: Inspecting the Kernel Expansion (Model Interpretation)\n",
        "# -----------------------------------------------------------------\n",
        "def analyze_support_vectors(X_train, y_train, C_val, gamma_val):\n",
        "    \"\"\"Analyzes the change in free and bounded SVs for decreasing C values.\"\"\"\n",
        "\n",
        "    print(\"\\n--- Task 2.3: Support Vector Analysis ---\")\n",
        "\n",
        "    # Define C values to test (the optimal C and two drastically lower values)\n",
        "    C_analysis_values = [C_val, C_val / 100, C_val / 1000]\n",
        "\n",
        "    print(f\"Rigorous Argument: Free SVs DECREASE, Bounded SVs INCREASE when C is lowered.\")\n",
        "    print(f\"{'C Value':<10} | {'Free SVs (0 < |a| < C)':<20} | {'Bounded SVs (|a| = C)':<30}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    for C_test in C_analysis_values:\n",
        "        # Train a new SVM with the test C value and fixed gamma\n",
        "        svm_model = SVC(kernel='rbf', C=C_test, gamma=gamma_val, random_state=42)\n",
        "        svm_model.fit(X_train, y_train)\n",
        "\n",
        "        # Access the dual coefficients (alpha_i)\n",
        "        abs_alphas = np.abs(svm_model.dual_coef_.ravel())\n",
        "\n",
        "        # Calculate SV counts (using small tolerance for floating point comparison)\n",
        "        bounded_svs = np.sum(abs_alphas >= C_test - 1e-5) # Bounded: alpha_i = C\n",
        "        free_svs = np.sum((abs_alphas > 1e-5) & (abs_alphas < C_test - 1e-5)) # Free: 0 < alpha_i < C\n",
        "\n",
        "        print(f\"{C_test:<10.4f} | {free_svs:<20} | {bounded_svs:<30}\")\n",
        "\n",
        "    print(\"\\nDeliverable: Code Snippets for Free and Bounded SV computation are within this function.\")\n",
        "    print(\"These results should verify the theory that Bounded SVs increase as C decreases.\")\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# MAIN EXECUTION\n",
        "# -----------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    X_train_s, y_train, X_test_s, y_test = load_and_preprocess_data()\n",
        "\n",
        "    # --- Task 2.2 Execution (Grid Search) ---\n",
        "    grid_search = run_grid_search(X_train_s, y_train)\n",
        "\n",
        "    # --- Final Report Results ---\n",
        "    final_C = grid_search.best_params_['C']\n",
        "    final_gamma = grid_search.best_params_['gamma']\n",
        "    final_svm = grid_search.best_estimator_\n",
        "\n",
        "    # Calculate Final Loss on Test Data (Deliverable)\n",
        "    final_test_accuracy = accuracy_score(y_test, final_svm.predict(X_test_s))\n",
        "    final_test_loss = 1 - final_test_accuracy\n",
        "\n",
        "    print(\"\\n=============================================\")\n",
        "    print(\"FINAL MODEL RESULTS (Task 2.2 Deliverables)\")\n",
        "    print(\"=============================================\")\n",
        "    print(f\"Optimal C:     {final_C}\")\n",
        "    print(f\"Optimal Gamma: {final_gamma}\")\n",
        "    print(f\"Test Loss (0-1 Error): {final_test_loss:.4f}\")\n",
        "    print(\"=============================================\")\n",
        "\n",
        "    # --- Task 2.3 Execution (SV Analysis) ---\n",
        "    analyze_support_vectors(X_train_s, y_train, final_C, final_gamma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayjssHPalb2U",
        "outputId": "f5c49434-e10c-4e24-d7ea-0d9633484154"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Task 2.1: Data Loading ---\n",
            "Number of training samples: 150\n",
            "Number of test samples:     164\n",
            "\n",
            "Training Class Frequencies:\n",
            "  Class -1: 45.33%\n",
            "  Class 1: 54.67%\n",
            "\n",
            "Verification of Transformed Test Data (Feature 10):\n",
            "  Mean (should be near 0): 0.0141\n",
            "  Variance (should be near 1): 1.0939\n",
            "\n",
            "--- Task 2.2: Starting Grid Search ---\n",
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "\n",
            "=============================================\n",
            "FINAL MODEL RESULTS (Task 2.2 Deliverables)\n",
            "=============================================\n",
            "Optimal C:     1.0\n",
            "Optimal Gamma: 0.01\n",
            "Test Loss (0-1 Error): 0.2073\n",
            "=============================================\n",
            "\n",
            "--- Task 2.3: Support Vector Analysis ---\n",
            "Rigorous Argument: Free SVs DECREASE, Bounded SVs INCREASE when C is lowered.\n",
            "C Value    | Free SVs (0 < |a| < C) | Bounded SVs (|a| = C)         \n",
            "----------------------------------------------------------------------\n",
            "1.0000     | 30                   | 55                            \n",
            "0.0100     | 4                    | 134                           \n",
            "0.0010     | 0                    | 136                           \n",
            "\n",
            "Deliverable: Code Snippets for Free and Bounded SV computation are within this function.\n",
            "These results should verify the theory that Bounded SVs increase as C decreases.\n"
          ]
        }
      ]
    }
  ]
}